---
title: "06. Linear regression and its cousins"
output: html_notebook
---

# Library and data

```{r}
library(AppliedPredictiveModeling)
library(corrplot)
library(caret)
library(dplyr)
library(compare)
library(e1071)
library(MASS)

data(solubility)
```


solTrainXtrans and solTestXtrans are Box-Cox transformed

## Data exploration

```{r}
correlations <- cor(solTrainX)
corrplot(correlations, order = "hclust")
```

## Check pairwise correlations over threshold 

```{r}

pairwise_corr <- function(correlations, threshold = threshold){
  nr <- nrow(correlations)
  sum(correlations > threshold | correlations < -threshold) - nr  
}

pairwise_corr(correlations, 0.8)
```

Cercare o creare una funzione che individui le coppie di varibili correlate oltre una certa soglia.


## Box-cox transform

Check variables with high skewness

```{r}
skewValues <- apply(solTrainX, 2, skewness)
sum(skewValues > 3)

solTrainX %>%
  summarize_all(skewness) 
```

Completare la funzione con trasmute, filter values over threeshold


```{r}
boxcox <- preProcess(solTrainX, method = "BoxCox") %>%
  predict(solTrainX)

comparison <- compare(solTrainXtrans, boxcox, allowAll=TRUE)

comparison$result
comparison$tM
```

Completare con selettore di pairwise correlations over threshold. Vedi dopo, esiste: è la funzione caret::findCorrelation() 


# OLS. Ordinary least square

## Standard OLS - lm()

Dobbiamo avere covariate e variabile risposta nello stesso dataset

```{r}
solTrain_full <- solTrainXtrans %>%
  cbind(solubility = solTrainY)

# Inutile
solTest_full <- solTestXtrans %>%
  cbind(solubility = solTestY)
```


Applichiamo OLS:

```{r}
olsFit1 <- lm(solubility ~ ., data = solTrain_full)

summary(olsFit1)
```


### Performance sugli stessi dati

Da summary() otteniamo le performance sugli stessi dati (prob. sovrastimate):
  
- $R^2$: 0.94

- $RMSE$: 0.55


### Performance su test set

Confrontiamo dati osservati e dati previsti su training set.

Per usare caret::defaultSummary() le colonne del dataframe devono chiamarsi obs e pred

```{r}
olsPred1 <- predict(olsFit1, solTestXtrans) 

# Nomi di colonna fissi
olsFitTestData1 <- data.frame(obs = solTestY, pred = olsPred1)

standardOLS <- defaultSummary(olsFitTestData1) %>% t()

performance_compare <- data.frame()

performance_compare <- performance_compare %>%
  rbind(standardOLS = standardOLS)
```

Esercizio: compute RMSE e Rsquared

```{r}
RMSE <- sqrt(sum((solTestY - olsPred1)^2)/length(solTestY))

R2 <- cor(solTestY, olsPred1)^2

RMSE
R2

```


## Robust OLS - MASS::

Robust linear regression with Huber approach.

Minimizza l'effetto delle osservazioni influenti (outlier), tramite una metrica alternativa ad SSE per la stima dei parametri: se la differenza tra residui e valori previsti è piccola, è usata al quadrato, altrimenti in valore assoluto.

```{r}
rolsFit1 <- rlm(solubility ~ ., data = solTrain_full)

summary(olsFit1)
```


### Performance su test set

```{r}
rolsPred1 <- predict(rolsFit1, solTestXtrans) 

# Nomi di colonna fissi
rolsFitTestData1 <- data.frame(obs = solTestY, pred = rolsPred1)

robustOLS <- defaultSummary(rolsFitTestData1) %>% t()

performance_compare <- performance_compare %>%
  rbind(robustOLS = robustOLS)

performance_compare
```

Lieve miglioramento di RMSE (ha senso calcolarlo? Sì perchè siamo su test set)


## k-fold OLS - caret::

Usiamo caret per una stima più precisa. 
Possiamo settare il tipo di resampling via trainControl().

Visto che il dataset ha tante osservazioni possiamo usare un k-fold cross-validation

```{r}
cv10Fold <- trainControl(method = "cv", number = 10)

set.seed(100)
olsFit2 <- train(x = solTrainXtrans, y = solTrainY,
                 method = "lm", trControl = cv10Fold)

# olsFit2

olsPred2 <- predict(olsFit2, solTestXtrans)

olsFitTestData2 <- data.frame(obs = solTestY, pred = olsPred2)
cvStandardOLS <- defaultSummary(olsFitTestData2) %>% t()

performance_compare <- performance_compare %>%
  rbind(cvStandardOLS = cvStandardOLS)

performance_compare
```


### Diagnostic plots

Nota che le funzioni predict() e resid() generano i valori previsti e i residui direttamente dal fit dell'lm

```{r}
xyplot(solTrainY ~ predict(olsFit2),
       # p: point, g: grid
       type = c("p", "g"),
       xlab = "Predicted", ylab = "Observed")
```

```{r}
xyplot(resid(olsFit2) ~ predict(olsFit2),
       # p: point, g: grid
       type = c("p", "g"),
       xlab = "Predicted", ylab = "Residual")
```

Sembra che la regressione colga bene la struttura dei dati: non notiamo pattern o outliers.

## OLS removing pairwise correlated predictors - caret::

```{r}
corThresh <- 0.9
tooHigh <- findCorrelation(cor(solTrainXtrans), corThresh)
```

findCorrelation() returns a vector of integers corresponding to columns to remove to reduce pair-wise correlations

```{r}
corPred <- names(solTrainXtrans)[tooHigh]

trainXfiltered <- solTrainXtrans[, -tooHigh]
testXfiltered <- solTestXtrans[, -tooHigh]
```

Train del modello e performance:

```{r}
olsFit3 <- train(trainXfiltered, solTrainY,
      method = "lm", trControl = cv10Fold)

olsFit3

olsPred3 <- predict(olsFit3, testXfiltered)

olsFitTestData3 <- data.frame(obs = solTestY, pred = olsPred3)
cvFilteredOLS <- defaultSummary(olsFitTestData3)

performance_compare <- performance_compare %>%
  rbind(cvFilteredOLS = cvFilteredOLS)

performance_compare
```

## Cross-validated robust OLS - caret::

Robust OLS richiede non singolarità della matrice di correlazione. Applichiamo pca preprocessing

```{r}
set.seed(100)

rolsFit2 <- train(solTrainXtrans, solTrainY,
                  method = "rlm",
                  preProcess = "pca",
                  trControl = cv10Fold)

rolsPred2 <- predict(rolsFit2, solTestXtrans)

rolsFitTestData2 <- data.frame(obs = solTestY, pred = rolsPred2)

cvRobustOLS <- defaultSummary(rolsFitTestData2)

performance_compare <- performance_compare %>%
  rbind(cvRobustOLS = cvRobustOLS)

performance_compare
```

Se nella funzione train() è stato fatto del preprocessing, questo tramite predict() si propaga al test set?



# Partial Least Square
