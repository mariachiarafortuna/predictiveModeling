---
title: "06. Linear regression and its cousins"
output: html_notebook
---

# Library and data

```{r}
library(AppliedPredictiveModeling)
library(corrplot)
library(caret)
library(dplyr)
library(compare)
library(e1071)
library(MASS)
library(pls)
library(elasticnet)

data(solubility)
```


solTrainXtrans and solTestXtrans are Box-Cox transformed

## Data exploration

```{r}
correlations <- cor(solTrainX)
corrplot(correlations, order = "hclust")
```

## Check pairwise correlations over threshold 

```{r}

pairwise_corr <- function(correlations, threshold = threshold){
  nr <- nrow(correlations)
  sum(correlations > threshold | correlations < -threshold) - nr  
}

pairwise_corr(correlations, 0.8)
```

Cercare o creare una funzione che individui le coppie di varibili correlate oltre una certa soglia.


## Box-cox transform

Check variables with high skewness

```{r}
skewValues <- apply(solTrainX, 2, skewness)
sum(skewValues > 3)

solTrainX %>%
  summarize_all(skewness) 
```

Completare la funzione con trasmute, filter values over threeshold


```{r}
boxcox <- preProcess(solTrainX, method = "BoxCox") %>%
  predict(solTrainX)

comparison <- compare(solTrainXtrans, boxcox, allowAll=TRUE)

comparison$result
comparison$tM
```

Completare con selettore di pairwise correlations over threshold. Vedi dopo, esiste: è la funzione caret::findCorrelation() 


# OLS. Ordinary least square

## Standard OLS - lm()

Dobbiamo avere covariate e variabile risposta nello stesso dataset

```{r}
solTrain_full <- solTrainXtrans %>%
  cbind(solubility = solTrainY)

# Inutile
solTest_full <- solTestXtrans %>%
  cbind(solubility = solTestY)
```


Applichiamo OLS:

```{r}
olsFit1 <- lm(solubility ~ ., data = solTrain_full)

summary(olsFit1)
```


### Performance sugli stessi dati

Da summary() otteniamo le performance sugli stessi dati (prob. sovrastimate):
  
- $R^2$: 0.94

- $RMSE$: 0.55


### Performance su test set

Confrontiamo dati osservati e dati previsti su training set.

Per usare caret::defaultSummary() le colonne del dataframe devono chiamarsi obs e pred

```{r}
olsPred1 <- predict(olsFit1, solTestXtrans) 

# Nomi di colonna fissi
olsFitTestData1 <- data.frame(obs = solTestY, pred = olsPred1)

standardOLS <- defaultSummary(olsFitTestData1) %>% t()

performance_compare <- data.frame()

performance_compare <- performance_compare %>%
  rbind(standardOLS = standardOLS)
```

Esercizio: compute RMSE e Rsquared

```{r}
RMSE <- sqrt(sum((solTestY - olsPred1)^2)/length(solTestY))

R2 <- cor(solTestY, olsPred1)^2

RMSE
R2

```


## Robust OLS - MASS::

Robust linear regression with Huber approach.

Minimizza l'effetto delle osservazioni influenti (outlier), tramite una metrica alternativa ad SSE per la stima dei parametri: se la differenza tra residui e valori previsti è piccola, è usata al quadrato, altrimenti in valore assoluto.

```{r}
rolsFit1 <- rlm(solubility ~ ., data = solTrain_full)

summary(olsFit1)
```


### Performance su test set

```{r}
rolsPred1 <- predict(rolsFit1, solTestXtrans) 

# Nomi di colonna fissi
rolsFitTestData1 <- data.frame(obs = solTestY, pred = rolsPred1)

robustOLS <- defaultSummary(rolsFitTestData1) %>% t()

performance_compare <- performance_compare %>%
  rbind(robustOLS = robustOLS)

performance_compare
```

Lieve miglioramento di RMSE (ha senso calcolarlo? Sì perchè siamo su test set)


## k-fold OLS - caret::

Usiamo caret per una stima più precisa. 
Possiamo settare il tipo di resampling via trainControl().

Visto che il dataset ha tante osservazioni possiamo usare un k-fold cross-validation

```{r}
cv10Fold <- trainControl(method = "cv", number = 10)

set.seed(100)
olsFit2 <- train(x = solTrainXtrans, y = solTrainY,
                 method = "lm", trControl = cv10Fold)

# olsFit2

olsPred2 <- predict(olsFit2, solTestXtrans)

olsFitTestData2 <- data.frame(obs = solTestY, pred = olsPred2)
cvStandardOLS <- defaultSummary(olsFitTestData2) %>% t()

performance_compare <- performance_compare %>%
  rbind(cvStandardOLS = cvStandardOLS)

performance_compare
```


### Diagnostic plots

Nota che le funzioni predict() e resid() generano i valori previsti e i residui direttamente dal fit dell'lm

```{r}
xyplot(solTrainY ~ predict(olsFit2),
       # p: point, g: grid
       type = c("p", "g"),
       xlab = "Predicted", ylab = "Observed")
```

```{r}
xyplot(resid(olsFit2) ~ predict(olsFit2),
       # p: point, g: grid
       type = c("p", "g"),
       xlab = "Predicted", ylab = "Residual")
```

Sembra che la regressione colga bene la struttura dei dati: non notiamo pattern o outliers.

## OLS removing pairwise correlated predictors - caret::

```{r}
corThresh <- 0.9
tooHigh <- findCorrelation(cor(solTrainXtrans), corThresh)
```

findCorrelation() returns a vector of integers corresponding to columns to remove to reduce pair-wise correlations

```{r}
corPred <- names(solTrainXtrans)[tooHigh]

trainXfiltered <- solTrainXtrans[, -tooHigh]
testXfiltered <- solTestXtrans[, -tooHigh]
```

Train del modello e performance:

```{r}
olsFit3 <- train(trainXfiltered, solTrainY,
      method = "lm", trControl = cv10Fold)

olsFit3

olsPred3 <- predict(olsFit3, testXfiltered)

olsFitTestData3 <- data.frame(obs = solTestY, pred = olsPred3)
cvFilteredOLS <- defaultSummary(olsFitTestData3)

performance_compare <- performance_compare %>%
  rbind(cvFilteredOLS = cvFilteredOLS)

performance_compare
```

## Cross-validated robust OLS - caret::

Robust OLS richiede non singolarità della matrice di correlazione. Applichiamo pca preprocessing

```{r}
set.seed(100)

rolsFit2 <- train(solTrainXtrans, solTrainY,
                  method = "rlm",
                  preProcess = "pca",
                  trControl = cv10Fold)

rolsPred2 <- predict(rolsFit2, solTestXtrans)

rolsFitTestData2 <- data.frame(obs = solTestY, pred = rolsPred2)

cvRobustOLS <- defaultSummary(rolsFitTestData2)

performance_compare <- performance_compare %>%
  rbind(cvRobustOLS = cvRobustOLS)

performance_compare
```

Se nella funzione train() è stato fatto del preprocessing, questo tramite predict() si propaga al test set?


# add_performance() function
 
Quasi-quotation version - not working

```{r}


# add_performance <- function(fit, testX, testY, performance_tab, 
#                             name){
#   name <- enquo(name)
#   row_name <- quo_name(name)
#   predicted <- predict(fit, testX)
#   obs_pred_tbl <- data.frame(obs = testY, pred = predicted)
#   new_performance <- defaultSummary(obs_pred_tbl)
#   performance_tab <- performance_tab %>%
#     rbind(!!row_name := new_performance)
#   return(performance_tab)
# }
# 
# add_performance(plsFit1, solTestXtrans, solTestY,
#                 performance_compare, cvPLS)


```


do.call() version - working

```{r}
add_performance <- function(fit, testX, testY, performance_tab, 
                            name){
  predicted <- predict(fit, testX)
  obs_pred_tbl <- data.frame(obs = testY, pred = predicted)
  new_performance <- defaultSummary(obs_pred_tbl)
  rownames_val <- rownames(performance_tab)
  performance_tab <- do.call(rbind, 
                             setNames(list(performance_tab,
                                           new_performance), 
                                      list("", name)))
  return(performance_tab)
}

# add_performance(plsFit1, solTestXtrans, solTestY,
#                 performance_compare, "cvPLS")
```


# Partial Least Square - caret::, da pls::

Il numero di componenti è un parametro di tuning. Usando caret::train() possiamo stimare il valore migliore all'interno di una griglia (vettore)

```{r}
set.seed(100)
plsFit1 <- train(solTrainXtrans, solTrainY,
                 method = "pls",
                 preProcess = c("center", "scale"),
                 trControl = cv10Fold,
                 tuneLength = 30)
plsFit1

performance_compare <- add_performance(plsFit1, 
                                       solTestXtrans, solTestY,
                                       performance_compare, 
                                       "cvPLS")

```

### Plotting tuning parameters

```{r}
ggplot(plsFit1) +
  geom_line(col = "red") +
  geom_point(col = "red") +
  theme_minimal()
```


# Ridge regression - caret::, da MASS::

Penalizza SSE nei minimi quadrati aggungendo il fattore di penalizzazione di secondo ordine (quadrato). 

In formula:

$SSE_{L2} = \sum_{i=1}^n(y_i - \hat{y_i})^2 + \lambda \sum_{j=1}^P \beta_j^2$

L'effetto è che le stime dei parametri crescono solo se ciò causa una riduzione proporzionale dell'SSE. Chiamato anche metodo di shrinkage (restringimento). Lambda è parametro di tuning.

Su caret possiamo definirlo passando all'argomento tuneGrid un dataframe con i valori di interesse da verificare.


```{r}
lambda_vec <- data.frame(.lambda = seq(0, 1, by = 0.05))
  
ridgeFit1 <- train(solTrainXtrans, solTrainY,
                   method = "ridge",
                   preProcess = c("center", "scale"),
                   trControl = cv10Fold,
                   tuneGrid = lambda_vec)

ridgeFit1

performance_compare <- add_performance(ridgeFit1, 
                                       solTestXtrans, solTestY,
                                       performance_compare, 
                                       "ridgeRegression")
```


# LASSO & Elastic Net 

Lasso penalizza SSE nei minimi quadrati aggungendo un fattore di penalizzazione di primo ordine (quadrato). 

In formula:

$SSE_{L1} = \sum_{i=1}^n(y_i - \hat{y_i})^2 + \lambda \sum_{j=1}^P |\beta_j|$

Elastic net considera sia il fattore di primo che di secondo ordine:

$SSE_{enet} = \sum_{i=1}^n(y_i - \hat{y_i})^2 + \lambda_1 \sum_{j=1}^P |\beta_j| + \lambda_2 \sum_{j=1}^P \beta_j^2$

Nell'elastic net utiliziamo come parametro di tuning sia lambda, sia la frazione rispetto alla full solution (non possiamo fare una griglia dei due lambda?)

```{r}
set.seed(100)

enetTune <- expand.grid(.lambda = c(0, 0.01, 0.1),
                       .fraction  = seq(.05, 1, length = 20) )
  
enetFit1 <- train(solTrainXtrans, solTrainY,
                   method = "enet",
                   preProcess = c("center", "scale"),
                   trControl = cv10Fold,
                   tuneGrid = enetTune)

enetFit1

performance_compare <- add_performance(enetFit1, 
                                       solTestXtrans, solTestY,
                                       performance_compare, 
                                       "elasticNet")
```

### Elastic net tuning plot

```{r}
ggplot(enetFit1)
```

### Final model predictors

Come capisco qual è il modello finale? 
```{r}
summary(enetFit1)

# enetFit1$finalModel
```

